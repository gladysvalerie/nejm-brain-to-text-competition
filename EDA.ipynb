{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gladysvalerie/nejm-brain-to-text-competition/blob/gladys/EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHWC-Sxe_uyq"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Initialize dictionaries to store data for each category\n",
        "train_data = []\n",
        "test_data = []\n",
        "validation_data = []\n",
        "other_data = []  # For anything that doesn't match the above categories\n",
        "\n",
        "with os.scandir('hdf5_data_final') as path:\n",
        "    for folder in path:\n",
        "        if folder.is_dir():\n",
        "            print(f\"Processing folder: {folder.name}\")\n",
        "            \n",
        "            with os.scandir(folder.path) as subfolder:\n",
        "                for file in subfolder:\n",
        "                    if file.name.endswith((\".h5\", \".hdf5\")):\n",
        "                        print(f\"  Processing file: {file.name}\")\n",
        "                        \n",
        "                        # Determine category based on file name\n",
        "                        file_lower = file.name.lower()\n",
        "                        if 'test' in file_lower and not 'testing' in file_lower:\n",
        "                            category = 'test'\n",
        "                            target_list = test_data\n",
        "                        elif 'train' in file_lower:\n",
        "                            category = 'train'\n",
        "                            target_list = train_data\n",
        "                        elif 'val' in file_lower or 'valid' in file_lower:\n",
        "                            category = 'validation'\n",
        "                            target_list = validation_data\n",
        "                        else:\n",
        "                            category = 'other'\n",
        "                            target_list = other_data\n",
        "                            \n",
        "                        print(f\"    Categorized as: {category}\")\n",
        "                        \n",
        "                        try:\n",
        "                            with h5py.File(file.path, \"r\") as f:\n",
        "                                # First identify the datasets you want\n",
        "                                datasets_to_extract = []\n",
        "                                \n",
        "                                def find_datasets(name, obj):\n",
        "                                    if isinstance(obj, h5py.Dataset):\n",
        "                                        datasets_to_extract.append(name)\n",
        "                                \n",
        "                                # Find all datasets in the file\n",
        "                                f.visititems(find_datasets)\n",
        "                                \n",
        "                                # Extract trial_id and parent_id if they exist\n",
        "                                trial_id = None\n",
        "                                parent_id = None\n",
        "                                \n",
        "                                # Look for trial_id and parent_id in dataset names or attributes\n",
        "                                for ds_path in datasets_to_extract:\n",
        "                                    if 'trial_id' in ds_path.lower():\n",
        "                                        trial_id = np.array(f[ds_path]).tolist()\n",
        "                                    if 'parent_id' in ds_path.lower():\n",
        "                                        parent_id = np.array(f[ds_path]).tolist()\n",
        "                                        \n",
        "                                # Extract data from each dataset\n",
        "                                for ds_path in datasets_to_extract:\n",
        "                                    try:\n",
        "                                        dataset = f[ds_path]\n",
        "                                        # Convert to numpy array and then to a regular Python object\n",
        "                                        data_array = np.array(dataset)\n",
        "                                        \n",
        "                                        # Create a record for this dataset\n",
        "                                        record = {\n",
        "                                            \"Category\": category,\n",
        "                                            \"Folder\": folder.name,\n",
        "                                            \"File\": file.name,\n",
        "                                            \"Dataset\": ds_path,\n",
        "                                            \"Data\": data_array,\n",
        "                                            \"Shape\": data_array.shape,\n",
        "                                            \"DType\": data_array.dtype,\n",
        "                                            \"Trial_ID\": trial_id,\n",
        "                                            \"Parent_ID\": parent_id\n",
        "                                        }\n",
        "                                        target_list.append(record)\n",
        "                                    except Exception as e:\n",
        "                                        print(f\"    Error extracting dataset {ds_path}: {e}\")\n",
        "                        except Exception as e:\n",
        "                            print(f\"    Error opening file {file.name}: {e}\")\n",
        "\n",
        "# Create DataFrames from the collected data\n",
        "df_train = pd.DataFrame(train_data)\n",
        "df_test = pd.DataFrame(test_data)\n",
        "df_validation = pd.DataFrame(validation_data)\n",
        "df_other = pd.DataFrame(other_data)\n",
        "\n",
        "# Display summary for each category\n",
        "print(\"\\n=== Summary of Data ===\")\n",
        "print(f\"Train data: {len(df_train)} datasets\")\n",
        "print(f\"Test data: {len(df_test)} datasets\")\n",
        "print(f\"Validation data: {len(df_validation)} datasets\")\n",
        "print(f\"Other data: {len(df_other)} datasets\")\n",
        "\n",
        "# Save each category to separate CSV files (just the metadata)\n",
        "if not df_train.empty:\n",
        "    df_train[['Folder', 'File', 'Dataset', 'Shape', 'DType', 'Trial_ID', 'Parent_ID']].to_csv(\"train_data_summary.csv\", index=False)\n",
        "    print(\"Saved train data summary\")\n",
        "    \n",
        "if not df_test.empty:\n",
        "    df_test[['Folder', 'File', 'Dataset', 'Shape', 'DType', 'Trial_ID', 'Parent_ID']].to_csv(\"test_data_summary.csv\", index=False)\n",
        "    print(\"Saved test data summary\")\n",
        "    \n",
        "if not df_validation.empty:\n",
        "    df_validation[['Folder', 'File', 'Dataset', 'Shape', 'DType', 'Trial_ID', 'Parent_ID']].to_csv(\"validation_data_summary.csv\", index=False)\n",
        "    print(\"Saved validation data summary\")\n",
        "    \n",
        "if not df_other.empty:\n",
        "    df_other[['Folder', 'File', 'Dataset', 'Shape', 'DType', 'Trial_ID', 'Parent_ID']].to_csv(\"other_data_summary.csv\", index=False)\n",
        "    print(\"Saved other data summary\")\n",
        "\n",
        "# Display preview of each DataFrame if not empty\n",
        "if not df_train.empty:\n",
        "    print(\"\\nTrain data preview:\")\n",
        "    print(df_train[['Folder', 'File', 'Dataset', 'Shape', 'Trial_ID', 'Parent_ID']].head(5))\n",
        "    \n",
        "if not df_test.empty:\n",
        "    print(\"\\nTest data preview:\")\n",
        "    print(df_test[['Folder', 'File', 'Dataset', 'Shape', 'Trial_ID', 'Parent_ID']].head(5))\n",
        "    \n",
        "if not df_validation.empty:\n",
        "    print(\"\\nValidation data preview:\")\n",
        "    print(df_validation[['Folder', 'File', 'Dataset', 'Shape', 'Trial_ID', 'Parent_ID']].head(5))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPTUuuMRnFHbGoUZEEIXDIX",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
